{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io, os,sys,types\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "from torch import autograd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import random\n",
    "import scipy.io\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import self_attention,Fusion_block,CCA\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import optuna\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import pretrainedmodels\n",
    "from vit_pytorch import ViT\n",
    "from pytorch_pretrained_vit import ViT\n",
    "from networks import vit_seg_configs\n",
    "\n",
    "from networks.model import get_Model\n",
    "\n",
    "# from lion_pytorch import Lion\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nni\n",
    "from nni.experiment import Experiment\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'traindata_dir': '/path/to/train_img_dir',\n",
    "    'valdata_dir': '/path/to/val_img_dir',\n",
    "    'testdata_dir': '/path/to/test_img_dir',\n",
    "    'modal_dir': '/path/to/model_parameters/',\n",
    "    'log_dir': '/path/to/training_log/',\n",
    "    'num_classes': 2,\n",
    "    'contrastive_center_loss_lambda': 0.5,\n",
    "    'contrastive_center_loss_delta': 0.001,\n",
    "    'center_learning_rate': 0.00001,\n",
    "    'train_batch_size': 16, \n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 32,\n",
    "    'num_epochs': 200,\n",
    "    'patient_epoch': 20,\n",
    "    'l_lr': 0.00002,\n",
    "    'initial_lr': 0.00001,\n",
    "    'learning_rate': 0.00005,\n",
    "    'S_S_GAP': [0.1,0.1,0.1,0.1,0.1],\n",
    "    'w_momentum': 0.9,\n",
    "    'w_weight_decay': 0.00001,\n",
    "    'workers': 4,\n",
    "    'seed': 42,\n",
    "    'hidden_dim': 512,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.5,\n",
    "    'loss-weight': torch.tensor(['class_0_weight',...,'class_c_weight'], dtype=torch.float32),\n",
    "    'seg-pretrained-weight':'/path/to/seg/model_pretrained_weight/U_Net.pth',\n",
    "    'seg_model_name':'U_Net_mid_output'#{transUnet:'transUnet',AttentionUnet:'AttentionUnet',transUnet_feature_fuse}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegImgNet(nn.Module):\n",
    "    def __init__(self, convNeXt_raw, convNeXt_seg, seg_Net, classes = 2, hidden_dim=512, n_layers=2, dropout=0.5):\n",
    "        super(SegImgNet, self).__init__()\n",
    "        self.seg_Net = seg_Net\n",
    "        convNeXt_raw.head.fc = nn.Linear(1024,1024)\n",
    "        convNeXt_seg.head.fc = nn.Linear(1024,1024)\n",
    "        self.convNeXt_raw_stem = convNeXt_raw.stem\n",
    "        self.convNeXt_seg_stem = convNeXt_seg.stem\n",
    "        \n",
    "        self.Unet_stage_0_feature_transform = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_1_feature_transform = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_2_feature_transform = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_3_feature_transform = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.convNeXt_seg_stage0 = convNeXt_seg.stages[0]\n",
    "        self.convNeXt_seg_stage1 = convNeXt_seg.stages[1]\n",
    "        self.convNeXt_seg_stage2 = convNeXt_seg.stages[2]\n",
    "        self.convNeXt_seg_stage3 = convNeXt_seg.stages[3]\n",
    "\n",
    "        self.convNeXt_raw_stage0 = convNeXt_raw.stages[0]\n",
    "        self.convNeXt_raw_stage1 = convNeXt_raw.stages[1]\n",
    "        self.convNeXt_raw_stage2 = convNeXt_raw.stages[2]\n",
    "        self.convNeXt_raw_stage3 = convNeXt_raw.stages[3]\n",
    "\n",
    "        self.convNeXt_raw_head = convNeXt_raw.head\n",
    "        self.convNeXt_seg_head = convNeXt_seg.head\n",
    "\n",
    "        self.convNeXt_raw_linear1 = nn.Linear(1024,512)\n",
    "        self.convNeXt_raw_relu1 = nn.GELU()\n",
    "        self.convNeXt_raw_linear2 = nn.Linear(512,512)\n",
    "        self.convNeXt_raw_relu2 = nn.GELU()\n",
    "        # self.convNeXt_raw_linear3 = nn.Linear(512,2)\n",
    "\n",
    "        self.convNeXt_seg_linear1 = nn.Linear(1024,512)\n",
    "        self.convNeXt_seg_relu1 = nn.GELU()\n",
    "        self.convNeXt_seg_linear2 = nn.Linear(512,512)\n",
    "        self.convNeXt_seg_relu2 = nn.GELU()\n",
    "        # self.convNeXt_seg_linear3 = nn.Linear(512,2)\n",
    "\n",
    "        self.linear1 = nn.Linear(1024,hidden_dim)\n",
    "        self.relu1 = nn.GELU()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_dim, classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        seg,unet_feature_map0,unet_feature_map1,unet_feature_map2,unet_feature_map3 = self.seg_Net(x)\n",
    "\n",
    "        seg_mask = seg[:,1,:,:]\n",
    "        seg_mask = seg_mask.unsqueeze(1)\n",
    "        seg_mask = seg_mask.repeat(1,3,1,1)\n",
    "        seg_raw = x*seg_mask\n",
    "\n",
    "        convNeXt_raw_output = self.convNeXt_raw_stem(x)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_stem(seg_raw)\n",
    "\n",
    "        convNeXt_raw_stage0_feature = self.convNeXt_raw_stage0(convNeXt_raw_output)\n",
    "        convNeXt_seg_stage0_feature = self.convNeXt_seg_stage0(convNeXt_seg_output)\n",
    "        Unet_stage_0_feature = self.Unet_stage_0_feature_transform(unet_feature_map0)\n",
    "        convNeXt_seg_stage1_input = F.sigmoid(Unet_stage_0_feature) * convNeXt_seg_stage0_feature\n",
    "\n",
    "        convNeXt_raw_stage1_feature = self.convNeXt_raw_stage1(convNeXt_raw_stage0_feature)\n",
    "        convNeXt_seg_stage1_feature = self.convNeXt_seg_stage1(convNeXt_seg_stage1_input)\n",
    "        Unet_stage_1_feature = self.Unet_stage_1_feature_transform(unet_feature_map1)\n",
    "        convNeXt_seg_stage2_input = F.sigmoid(Unet_stage_1_feature) * convNeXt_seg_stage1_feature\n",
    "\n",
    "        convNeXt_raw_stage2_feature = self.convNeXt_raw_stage2(convNeXt_raw_stage1_feature)\n",
    "        convNeXt_seg_stage2_feature = self.convNeXt_seg_stage2(convNeXt_seg_stage2_input)\n",
    "        Unet_stage_2_feature = self.Unet_stage_2_feature_transform(unet_feature_map2)\n",
    "        convNeXt_seg_stage3_input = F.sigmoid(Unet_stage_2_feature) * convNeXt_seg_stage2_feature\n",
    "\n",
    "        convNeXt_raw_stage3_feature = self.convNeXt_raw_stage3(convNeXt_raw_stage2_feature)\n",
    "        convNeXt_seg_stage3_feature = self.convNeXt_seg_stage3(convNeXt_seg_stage3_input)\n",
    "        Unet_stage_3_feature = self.Unet_stage_3_feature_transform(unet_feature_map3)\n",
    "        convNeXt_seg_stage3_feature = F.sigmoid(Unet_stage_3_feature) * convNeXt_seg_stage3_feature\n",
    "        \n",
    "        convNeXt_raw_output = self.convNeXt_raw_head(convNeXt_raw_stage3_feature)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_head(convNeXt_seg_stage3_feature)\n",
    "\n",
    "\n",
    "        convNeXt_raw_output = self.convNeXt_raw_linear1(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_relu1(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_linear2(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_relu2(convNeXt_raw_output)\n",
    "        # convNeXt_raw_logits = self.convNeXt_raw_linear3(convNeXt_raw_output)\n",
    "\n",
    "        convNeXt_seg_output = self.convNeXt_seg_linear1(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_relu1(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_linear2(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_relu2(convNeXt_seg_output)\n",
    "        # convNeXt_seg_logits = self.convNeXt_seg_linear3(convNeXt_seg_output)\n",
    "\n",
    "\n",
    "        \n",
    "        output = torch.cat((convNeXt_raw_output, convNeXt_seg_output),1)\n",
    "        output = self.linear1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.mlp_layers(output)\n",
    "        logits = self.linear2(output)\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs, logits, output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, test_prob_dir, test_label_dir):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "    \n",
    "        for name, parameters in model.named_parameters():\n",
    "            parameters.requires_grad = False\n",
    "\n",
    "        num_correct, num_samples = 0, len(loader.dataset)\n",
    "\n",
    "        test_batch_index = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "\n",
    "            x_var = x.to(device)\n",
    "            scores, _, _ = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            if test_batch_index == 0:\n",
    "                y_test = y.cpu().detach().numpy()\n",
    "                y_probs = scores.cpu().detach().numpy()\n",
    "                y_pred = preds.numpy()\n",
    "            else:\n",
    "                y_test = np.append(y_test, y.cpu().detach().numpy())\n",
    "                y_probs = np.vstack((y_probs, scores.cpu().detach().numpy()))\n",
    "                y_pred = np.append(y_pred, preds.cpu().detach().numpy())\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            test_batch_index += 1\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        # print(y_test.shape)\n",
    "        y_probs = y_probs[...,1:]\n",
    "        # print(y_probs.shape)\n",
    "        # print(y_pred.shape)\n",
    "    #     test_prob_dir = './data/eye_image/fold_0/Resnet_Aug_rwROSE_test_prob.txt'\n",
    "#         np.savetxt(test_prob_dir, y_probs ,fmt='%.10e', delimiter=\" \") \n",
    "#         np.savetxt(test_label_dir, y_test ,fmt='%.10e', delimiter=\" \")\n",
    "\n",
    "        print('Test accuracy: {:.2f}% ({}/{})'.format(\n",
    "            100.*acc,\n",
    "            num_correct,\n",
    "            num_samples,\n",
    "            ))\n",
    "\n",
    "        AUC_score = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "        AUPRC_score = average_precision_score(y_test, y_probs)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "\n",
    "        \n",
    "        print('AUC:')\n",
    "        print(AUC_score)\n",
    "        print('AUPRC:')\n",
    "        print(AUPRC_score)\n",
    "        print('recall:')\n",
    "        print(recall)\n",
    "        print('specificity:')\n",
    "        print(specificity)\n",
    "        print('F1:')\n",
    "        print(f1)\n",
    "        print('precision:')\n",
    "        print(precision)\n",
    "        print('Accuracy:')\n",
    "        print(accuracy)\n",
    "\n",
    "    return AUC_score, AUPRC_score, recall, specificity, f1, precision, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###model name: transUnet:'transUnet', transUnet_feature_fuse:'transUnet_feature_fuse', AttentionUnet:'AttentionUnet', duckNet:'duckNet', Unet:'Unet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.data = datasets.ImageFolder(root=root_dir).imgs\n",
    "        \n",
    "        \n",
    "        self.imgs = [x[0] for x in self.data]\n",
    "        self.label = [x[1] for x in self.data]\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        img_seg = self.imgs[idx]\n",
    "        img_seg = Image.open(img_seg)\n",
    "        # img_org = img_seg.copy()\n",
    "        # img_org = np.asarray(img_org)\n",
    "        # img_org = cv2.cvtColor(img_org, cv2.COLOR_RGB2GRAY)\n",
    "        # img_org = Image.fromarray(img_org)\n",
    "        \n",
    "        img_seg= self.transform(img_seg)\n",
    "        # img_org = self.transform(img_org)\n",
    "        return img_seg,self.label[idx]#return the processed image, original image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "CustomImageDataset(param['testdata_dir'], transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "])),\n",
    "batch_size=param['val_batch_size'], shuffle=False,\n",
    "num_workers=param['workers'], pin_memory=True)\n",
    "\n",
    "model = get_Model(model_name=param['model_name'])\n",
    "model.load_state_dict(torch.load(param['seg-pretrained-weight']))\n",
    "\n",
    "ConvNext_raw = timm.create_model(\"hf_hub:timm/convnext_base.fb_in22k_ft_in1k\", pretrained=True)\n",
    "ConvNext_seg = timm.create_model(\"hf_hub:timm/convnext_base.fb_in22k_ft_in1k\", pretrained=True)\n",
    "net = SegImgNet(ConvNext_raw,ConvNext_seg,model,param['num_classes'])\n",
    "net.to(device)\n",
    "for name, parameters in net.named_parameters():\n",
    "    parameters.requires_grad = False\n",
    "\n",
    "net_dir = os.path.join(model_dir, 'SegImgNet' + '_model_parameter2.pkl')\n",
    "test_prob_dir = os.path.join(log_dir, 'SegImgNet_test_prob.txt')\n",
    "test_label_dir = os.path.join(log_dir, 'SegImgNet_test_label.txt')\n",
    "AUC_score, AUPRC_score, recall, specificity, f1, precision, accuracy = test(net, test_loader, test_prob_dir, test_label_dir)\n",
    "print('AUC_score:', AUC_score)\n",
    "print('AUPRC_score:', AUPRC_score)\n",
    "print('recall:', recall)\n",
    "print('specificity:', specificity)\n",
    "print('f1:', f1)\n",
    "print('precision:', precision)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
