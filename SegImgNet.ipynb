{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransUnet feature Merge using different method and Pretrained on the new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io, os,sys,types\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from torch import autograd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import random\n",
    "import scipy.io\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "\n",
    "from networks.model import get_Model\n",
    "\n",
    "# from lion_pytorch import Lion\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset path, model weight path\n",
    "root_dir = '/path/to/data/'\n",
    "model_dir = '/path/to/model_weight/'\n",
    "\n",
    "dataset_categories = ['train_set','val_set','test_set'] #feel free to set trainset, valset, testset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegImgNet(nn.Module):\n",
    "    def __init__(self, convNeXt_raw, convNeXt_seg, seg_Net, num_classes=2, hidden_dim=512, n_layers=2, dropout=0.5):\n",
    "        super(SegImgNet, self).__init__()\n",
    "        self.seg_Net = seg_Net\n",
    "        convNeXt_raw.head.fc = nn.Linear(1024,1024)\n",
    "        convNeXt_seg.head.fc = nn.Linear(1024,1024)\n",
    "        self.convNeXt_raw_stem = convNeXt_raw.stem\n",
    "        self.convNeXt_seg_stem = convNeXt_seg.stem\n",
    "        \n",
    "        self.Unet_stage_0_feature_transform = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_1_feature_transform = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_2_feature_transform = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        self.Unet_stage_3_feature_transform = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.convNeXt_seg_stage0 = convNeXt_seg.stages[0]\n",
    "        self.convNeXt_seg_stage1 = convNeXt_seg.stages[1]\n",
    "        self.convNeXt_seg_stage2 = convNeXt_seg.stages[2]\n",
    "        self.convNeXt_seg_stage3 = convNeXt_seg.stages[3]\n",
    "\n",
    "        self.convNeXt_raw_stage0 = convNeXt_raw.stages[0]\n",
    "        self.convNeXt_raw_stage1 = convNeXt_raw.stages[1]\n",
    "        self.convNeXt_raw_stage2 = convNeXt_raw.stages[2]\n",
    "        self.convNeXt_raw_stage3 = convNeXt_raw.stages[3]\n",
    "\n",
    "        self.convNeXt_raw_head = convNeXt_raw.head\n",
    "        self.convNeXt_seg_head = convNeXt_seg.head\n",
    "\n",
    "        self.convNeXt_raw_linear1 = nn.Linear(1024,512)\n",
    "        self.convNeXt_raw_relu1 = nn.GELU()\n",
    "        self.convNeXt_raw_linear2 = nn.Linear(512,512)\n",
    "        self.convNeXt_raw_relu2 = nn.GELU()\n",
    "        # self.convNeXt_raw_linear3 = nn.Linear(512,2)\n",
    "\n",
    "        self.convNeXt_seg_linear1 = nn.Linear(1024,512)\n",
    "        self.convNeXt_seg_relu1 = nn.GELU()\n",
    "        self.convNeXt_seg_linear2 = nn.Linear(512,512)\n",
    "        self.convNeXt_seg_relu2 = nn.GELU()\n",
    "        # self.convNeXt_seg_linear3 = nn.Linear(512,2)\n",
    "\n",
    "        self.linear1 = nn.Linear(1024,hidden_dim)\n",
    "        self.relu1 = nn.GELU()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_dim,num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        seg,unet_feature_map0,unet_feature_map1,unet_feature_map2,unet_feature_map3 = self.seg_Net(x)\n",
    "\n",
    "        seg_mask = seg[:,1,:,:]\n",
    "        seg_mask = seg_mask.unsqueeze(1)\n",
    "        seg_mask = seg_mask.repeat(1,3,1,1)\n",
    "        seg_raw = x*seg_mask\n",
    "\n",
    "        convNeXt_raw_output = self.convNeXt_raw_stem(x)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_stem(seg_raw)\n",
    "\n",
    "        convNeXt_raw_stage0_feature = self.convNeXt_raw_stage0(convNeXt_raw_output)\n",
    "        convNeXt_seg_stage0_feature = self.convNeXt_seg_stage0(convNeXt_seg_output)\n",
    "        Unet_stage_0_feature = self.Unet_stage_0_feature_transform(unet_feature_map0)\n",
    "        convNeXt_seg_stage1_input = F.sigmoid(Unet_stage_0_feature) * convNeXt_seg_stage0_feature\n",
    "\n",
    "        convNeXt_raw_stage1_feature = self.convNeXt_raw_stage1(convNeXt_raw_stage0_feature)\n",
    "        convNeXt_seg_stage1_feature = self.convNeXt_seg_stage1(convNeXt_seg_stage1_input)\n",
    "        Unet_stage_1_feature = self.Unet_stage_1_feature_transform(unet_feature_map1)\n",
    "        convNeXt_seg_stage2_input = F.sigmoid(Unet_stage_1_feature) * convNeXt_seg_stage1_feature\n",
    "\n",
    "        convNeXt_raw_stage2_feature = self.convNeXt_raw_stage2(convNeXt_raw_stage1_feature)\n",
    "        convNeXt_seg_stage2_feature = self.convNeXt_seg_stage2(convNeXt_seg_stage2_input)\n",
    "        Unet_stage_2_feature = self.Unet_stage_2_feature_transform(unet_feature_map2)\n",
    "        convNeXt_seg_stage3_input = F.sigmoid(Unet_stage_2_feature) * convNeXt_seg_stage2_feature\n",
    "\n",
    "        convNeXt_raw_stage3_feature = self.convNeXt_raw_stage3(convNeXt_raw_stage2_feature)\n",
    "        convNeXt_seg_stage3_feature = self.convNeXt_seg_stage3(convNeXt_seg_stage3_input)\n",
    "        Unet_stage_3_feature = self.Unet_stage_3_feature_transform(unet_feature_map3)\n",
    "        convNeXt_seg_stage3_feature = F.sigmoid(Unet_stage_3_feature) * convNeXt_seg_stage3_feature\n",
    "        \n",
    "        convNeXt_raw_output = self.convNeXt_raw_head(convNeXt_raw_stage3_feature)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_head(convNeXt_seg_stage3_feature)\n",
    "\n",
    "\n",
    "        convNeXt_raw_output = self.convNeXt_raw_linear1(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_relu1(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_linear2(convNeXt_raw_output)\n",
    "        convNeXt_raw_output = self.convNeXt_raw_relu2(convNeXt_raw_output)\n",
    "        # convNeXt_raw_logits = self.convNeXt_raw_linear3(convNeXt_raw_output)\n",
    "\n",
    "        convNeXt_seg_output = self.convNeXt_seg_linear1(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_relu1(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_linear2(convNeXt_seg_output)\n",
    "        convNeXt_seg_output = self.convNeXt_seg_relu2(convNeXt_seg_output)\n",
    "        # convNeXt_seg_logits = self.convNeXt_seg_linear3(convNeXt_seg_output)\n",
    "\n",
    "\n",
    "        \n",
    "        output = torch.cat((convNeXt_raw_output, convNeXt_seg_output),1)\n",
    "        output = self.linear1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.mlp_layers(output)\n",
    "        logits = self.linear2(output)\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return probs, logits\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three loss\n",
    "def train(model, loss_fn, optimizer, scheduler, param, loader_train, loader_val, modal_dir):\n",
    "\n",
    "    model.train()\n",
    "    max_auc = 0\n",
    "\n",
    "    checkpoint_epoch = 0\n",
    "    patient_epoch = 0\n",
    "    for epoch in range(param['num_epochs']):\n",
    "        model.train()\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, param['num_epochs']))\n",
    "    #         adjust_learning_rate(optimizer, epoch)\n",
    "        epoch_loss = 0\n",
    "        with torch.enable_grad():\n",
    "            for t, (x, y) in enumerate(loader_train):\n",
    "\n",
    "                x_var, y_var = x.to(device), y.to(device)\n",
    "                _, scores = model(x_var)\n",
    "                loss = loss_fn(scores, y_var)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "\n",
    "                if (t + 1) % 100 == 0:\n",
    "                    #print(loss.item())\n",
    "                    print('t = %d, loss = %.8f' % (t + 1, loss.item()))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "        #             nn.utils.clip_grad_norm_(model.parameters(), config['w_grad_clip'])\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        epoch_auc = validate(model, loader_val, param['S_S_GAP'])\n",
    "        patient_epoch = patient_epoch + 1\n",
    "        with torch.enable_grad():\n",
    "            if epoch_auc > max_auc:\n",
    "                max_auc = epoch_auc\n",
    "                best_epopch = epoch\n",
    "                torch.save(model.state_dict(), modal_dir)\n",
    "                patient_epoch = 0\n",
    "            scheduler.step(max_auc)\n",
    "\n",
    "        if patient_epoch > param['patient_epoch']:\n",
    "            print('reach patient epoch')\n",
    "            break\n",
    "    return checkpoint_epoch             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, gap):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        test_batch_index = 0\n",
    "        for x, y in loader:\n",
    "\n",
    "            x_var = x.to(device)\n",
    "            scores, _ = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            if test_batch_index == 0:\n",
    "                y_test = y.cpu().detach().numpy()\n",
    "                y_probs = scores.cpu().detach().numpy()\n",
    "                y_pred = preds.numpy()\n",
    "            else:\n",
    "                y_test = np.append(y_test, y.cpu().detach().numpy())\n",
    "                y_probs = np.vstack((y_probs, scores.cpu().detach().numpy()))\n",
    "                y_pred = np.append(y_pred, preds.cpu().detach().numpy())\n",
    "\n",
    "            test_batch_index += 1\n",
    "\n",
    "        # print(y_test.shape)\n",
    "        y_probs = y_probs[...,1:]\n",
    "        # print(y_probs.shape)\n",
    "        # print(y_pred.shape)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        AUC_score = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "        # f1 = f1_score(y_test, y_pred)\n",
    "        # accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        print('AUC_score:', AUC_score)\n",
    "        print('recall:', recall)\n",
    "        print('specificity:', specificity)\n",
    "\n",
    "        if abs(recall - specificity) >= gap:\n",
    "            return 0\n",
    "        else:\n",
    "            return AUC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, test_prob_dir, test_label_dir):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "    \n",
    "        for name, parameters in model.named_parameters():\n",
    "            parameters.requires_grad = False\n",
    "\n",
    "        num_correct, num_samples = 0, len(loader.dataset)\n",
    "\n",
    "        test_batch_index = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "\n",
    "            x_var = x.to(device)\n",
    "            scores, _ = model(x_var)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            if test_batch_index == 0:\n",
    "                y_test = y.cpu().detach().numpy()\n",
    "                y_probs = scores.cpu().detach().numpy()\n",
    "                y_pred = preds.numpy()\n",
    "            else:\n",
    "                y_test = np.append(y_test, y.cpu().detach().numpy())\n",
    "                y_probs = np.vstack((y_probs, scores.cpu().detach().numpy()))\n",
    "                y_pred = np.append(y_pred, preds.cpu().detach().numpy())\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            test_batch_index += 1\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        # print(y_test.shape)\n",
    "        y_probs = y_probs[...,1:]\n",
    "        # print(y_probs.shape)\n",
    "        # print(y_pred.shape)\n",
    "\n",
    "        np.savetxt(test_prob_dir, y_probs ,fmt='%.10e', delimiter=\" \") \n",
    "        np.savetxt(test_label_dir, y_test ,fmt='%.10e', delimiter=\" \")\n",
    "\n",
    "        print('Test accuracy: {:.2f}% ({}/{})'.format(\n",
    "            100.*acc,\n",
    "            num_correct,\n",
    "            num_samples,\n",
    "            ))\n",
    "\n",
    "        AUC_score = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "\n",
    "        \n",
    "        print('AUC:')\n",
    "        print(AUC_score)\n",
    "        print('recall:')\n",
    "        print(recall)\n",
    "        print('specificity:')\n",
    "        print(specificity)\n",
    "        print('F1:')\n",
    "        print(f1)\n",
    "        print('precision:')\n",
    "        print(precision)\n",
    "        print('Accuracy:')\n",
    "        print(accuracy)\n",
    "\n",
    "    return AUC_score, recall, specificity, f1, precision, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the segmentation model name, segmentation model weight path, and classification model training hyperparameters\n",
    "param = {\n",
    "    'seg-pretrained-weight':'/path/to/pretrained_seg_model_weight',\n",
    "    'seg_model_name':'U_Net_mid_output',\n",
    "\n",
    "    'num_classes': 2,   \n",
    "    'hidden_dim': 512,\n",
    "    'n_layers': 2,\n",
    "    'dropout': 0.5,\n",
    "    \n",
    "    'train_batch_size': 16, \n",
    "    'val_batch_size': 64,\n",
    "    'test_batch_size': 64,\n",
    "    'num_epochs': 200,\n",
    "    'patient_epoch': 20,\n",
    "    'learning_rate': 0.00005,\n",
    "    'initial_lr': 0.000001,\n",
    "    'S_S_GAP': 0.1,          # balance the sensitivity and specificity. Let them gap not go over S_S_GAP\n",
    "    'w_weight_decay': 0.001,\n",
    "    'workers': 4,\n",
    "    'seed': 42,\n",
    "    'loss-weight': [torch.tensor([1.15,1.85], dtype=torch.float32)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###model name: transUnet:'transUnet', transUnet_feature_fuse:'transUnet_feature_fuse', AttentionUnet:'AttentionUnet', duckNet:'duckNet', Unet:'Unet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.data = datasets.ImageFolder(root=root_dir).imgs\n",
    "        \n",
    "        \n",
    "        self.imgs = [x[0] for x in self.data]\n",
    "        self.label = [x[1] for x in self.data]\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        img_seg = self.imgs[idx]\n",
    "        img_seg = Image.open(img_seg)\n",
    "\n",
    "        \n",
    "        img_seg= self.transform(img_seg)\n",
    "        return img_seg,self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_AUC = []\n",
    "fold_F1 = []\n",
    "fold_Accuracy = []\n",
    "fold_Recall = []\n",
    "fold_Precision = []\n",
    "# fold_Sensitivity = []\n",
    "fold_Specificity = []\n",
    "checkpoint_epoch_list = []\n",
    "for i in range(5):\n",
    "    param['trainset_dir'] = os.path.join(root_dir,  'fold_'+ str(i), dataset_categories[0])\n",
    "    param['valset_dir'] = os.path.join(root_dir,  'fold_'+ str(i), dataset_categories[1])\n",
    "    param['testset_dir'] = os.path.join(root_dir,  'fold_'+ str(i), dataset_categories[2])\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    CustomImageDataset(param['trainset_dir'], transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomVerticalFlip(0.2),\n",
    "        transforms.RandomHorizontalFlip(0.2),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "    ])),\n",
    "    batch_size=param['train_batch_size'], shuffle=True,\n",
    "    num_workers=param['workers'], pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "    CustomImageDataset(param['valset_dir'], transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor()\n",
    "        \n",
    "    ])),\n",
    "    batch_size=param['val_batch_size'], shuffle=False,\n",
    "    num_workers=param['workers'], pin_memory=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "    CustomImageDataset(param['testset_dir'], transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor()\n",
    "        \n",
    "    ])),\n",
    "    batch_size=param['test_batch_size'], shuffle=False,\n",
    "    num_workers=param['workers'], pin_memory=True)\n",
    "\n",
    "    model = get_Model(model_name=param['seg_model_name'])\n",
    "    model.load_state_dict(torch.load(param['seg-pretrained-weight']))\n",
    "\n",
    "    ConvNext_raw = timm.create_model(\"hf_hub:timm/convnext_base.fb_in22k_ft_in1k\", pretrained=True)\n",
    "    ConvNext_seg = timm.create_model(\"hf_hub:timm/convnext_base.fb_in22k_ft_in1k\", pretrained=True)\n",
    "    net = SegImgNet(ConvNext_raw,ConvNext_seg,model,num_classes=param['num_classes'],hidden_dim=param['hidden_dim'],n_layers=param['n_layers'],dropout=param['dropout'])\n",
    "    net.to(device)\n",
    "    for name, parameters in net.named_parameters():\n",
    "        if \"seg_Net\" in name:\n",
    "            parameters.requires_grad = False\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=param['loss-weight'].to(device))\n",
    "    optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, net.parameters()), lr=param['learning_rate'], weight_decay=param['w_weight_decay'])\n",
    "    plateau_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5,threshold=1e-5, threshold_mode='abs', patience=10, min_lr=param['initial_lr'])\n",
    "    # for name, parameters in net.named_parameters():\n",
    "    #     if parameters.requires_grad:\n",
    "    #         print(name)\n",
    "    net_dir = os.path.join(model_dir, 'SegImgNet' + 'fold_'+ str(i) + dataset_categories[0]+'_model_parameter.pkl')\n",
    "    if os.path.exists(net_dir):\n",
    "        os.remove(net_dir)\n",
    "    checkpoint_epoch = train(net, criterion, optimizer, plateau_scheduler, param, train_loader, val_loader, net_dir)\n",
    "    checkpoint_epoch_list.append(checkpoint_epoch)\n",
    "    net.load_state_dict(torch.load(net_dir))\n",
    "    test_prob_dir = os.path.join(root_dir, 'fold_'+ str(i), 'SegImgNet'+dataset_categories[0]+'_test_prob.txt')\n",
    "    test_label_dir = os.path.join(root_dir, 'fold_'+ str(i), 'SegImgNet'+dataset_categories[0]+'_test_label.txt')\n",
    "    AUC_score, recall, specificity, f1, precision, accuracy = test(net, test_loader, test_prob_dir, test_label_dir)\n",
    "    fold_AUC.append(AUC_score)\n",
    "    fold_F1.append(f1)\n",
    "    fold_Accuracy.append(accuracy)\n",
    "    fold_Recall.append(recall)\n",
    "    fold_Precision.append(precision)\n",
    "    fold_Specificity.append(specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fold_AUC))\n",
    "print(len(fold_F1))\n",
    "print(len(fold_Accuracy))\n",
    "print(len(fold_Recall))\n",
    "print(len(fold_Precision))\n",
    "print(len(fold_Specificity))\n",
    "\n",
    "AUC_result = np.array(fold_AUC)\n",
    "F1_result = np.array(fold_F1)\n",
    "Accuracy_result = np.array(fold_Accuracy)\n",
    "Recall_result = np.array(fold_Recall)\n",
    "Precision_result = np.array(fold_Precision)\n",
    "Specificity_result = np.array(fold_Specificity)\n",
    "\n",
    "print(checkpoint_epoch_list)\n",
    "print('AUC_result')\n",
    "print(AUC_result)\n",
    "print('Recall_result')\n",
    "print(Recall_result)\n",
    "print('Specificity_result')\n",
    "print(Specificity_result)\n",
    "print('F1_result')\n",
    "print(F1_result)\n",
    "print('Precision_result')\n",
    "print(Precision_result)\n",
    "print('Accuracy_result')\n",
    "print(Accuracy_result)\n",
    "\n",
    "\n",
    "print('Avg_AUC:')\n",
    "print(np.mean(AUC_result))\n",
    "print('std_AUC:')\n",
    "print(np.std(AUC_result))\n",
    "\n",
    "print('Avg_Recall:')\n",
    "print(np.mean(Recall_result))\n",
    "print('std_Recall:')\n",
    "print(np.std(Recall_result))\n",
    "\n",
    "print('Avg_Specificity:')\n",
    "print(np.mean(Specificity_result))\n",
    "print('std_Specificity:')\n",
    "print(np.std(Specificity_result))\n",
    "\n",
    "print('Avg_F1:')\n",
    "print(np.mean(F1_result))\n",
    "print('std_F1:')\n",
    "print(np.std(F1_result))\n",
    "\n",
    "print('Avg_Precision:')\n",
    "print(np.mean(Precision_result))\n",
    "print('std_Precision:')\n",
    "print(np.std(Precision_result))\n",
    "\n",
    "print('Avg_Accuracy:')\n",
    "print(np.mean(Accuracy_result))\n",
    "print('std_Accuracy:')\n",
    "print(np.std(Accuracy_result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
